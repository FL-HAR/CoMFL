{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import decimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a02aa",
   "metadata": {},
   "source": [
    "## 0-1 watch file reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## SMART WATCH ################################################\n",
    "\n",
    "# List of CSV files\n",
    "pkl_files = ['accelerometer', 'bvp', 'eda','temperature']\n",
    "classes = ['Browsing on a Monitor','Hand Writing','Keyboard Typing','Reading Book',\n",
    "           'Stretching','Talking in Phone','walking and talking to phone',\n",
    "           'Walking Around','writing and talking to phone']\n",
    "\n",
    "base_path = \"D:/Download new/HAR\"\n",
    "base_path = \"E:/Software/HAR_2023_dataset/OneDrive_2023/Synchronized HAR Data\"\n",
    "\n",
    "directories = glob.glob(os.path.join(base_path, \"*-2023-*\"))\n",
    "\n",
    "client_set_watch = [ [] for i in range(35)]\n",
    "\n",
    "# Loop through each matched directory\n",
    "for directory in directories:\n",
    "    class_set = []\n",
    "    for class_name in classes:\n",
    "        watch_modal = []\n",
    "        for feature in pkl_files:\n",
    "            # Define file path\n",
    "            file_path = os.path.join(directory, class_name, \"Smartwatch\", \"smartwatch\", f\"{feature}.pkl\")\n",
    "            # set the time stamp based on accelerometer \n",
    "\n",
    "            # Check if file exists\n",
    "            if os.path.isfile(file_path):\n",
    "                # Read each CSV file\n",
    "                df = pd.read_pickle(file_path)\n",
    "\n",
    "                # Convert DataFrame to numpy array and append to the list\n",
    "                all_keys = list(df.keys())\n",
    "                #making timestamps\n",
    "                timestamps = np.arange(float(df['start_time_stamp']), float(df['start_time_stamp'] )\n",
    "                                       + 1000*len(df[all_keys[0]])/df['sample_rate'], 1000/df['sample_rate'])\n",
    "                df_values = np.array([df[key] for key in all_keys[:-2]])\n",
    "                timestamps = timestamps[0:np.shape(df_values)[1]]\n",
    "                df_values =  np.transpose(np.concatenate((np.expand_dims(timestamps,axis = 0), df_values), axis=0))\n",
    "                watch_modal.append(df_values)\n",
    "                #print(np.shape(df_values))\n",
    "            else:\n",
    "                #print(f\"File {file_path} not found.\")\n",
    "                watch_modal.append(['not available'])\n",
    "        class_set.append(watch_modal)\n",
    "    client_set_watch[int(directory[-2:])-1] = class_set ##directory[-2:] retrieves the ID\n",
    "    # Now 'class_set' is a list of numpy arrays for each class in the current directory\n",
    "    # You can process it here before moving to the next directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133d311",
   "metadata": {},
   "source": [
    "## 0-2 Phone file reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79000b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# SMART PHONE ##################################\n",
    "\n",
    "# List of CSV files\n",
    "csv_files = ['Lacc', 'accel', 'gravity','gyro','mag','orientation','rotation']\n",
    "classes = ['Browsing on a Monitor','Hand Writing','Keyboard Typing','Reading Book',\n",
    "           'Stretching','Talking in Phone','walking and talking to phone',\n",
    "           'Walking Around','writing and talking to phone']\n",
    "\n",
    "# Base path\n",
    "# Please enter the path directory for the dataset here\n",
    "base_path = \"E:/Software/HAR_2023_dataset/OneDrive_2023/Synchronized HAR Data\"\n",
    "# base_path = \"H:/Arash/HAR/HAR_2023_dataset/2023 - FL - HAR/data/Synchronized HAR Data\" # Office PC\n",
    "\n",
    "\n",
    "# Get all directories within base_path that match the pattern\n",
    "directories = glob.glob(os.path.join(base_path, \"*-2023-*\"))\n",
    "\n",
    "client_set_phone = [ [] for i in range(35)]\n",
    "# Loop through each matched directory\n",
    "for directory in directories:\n",
    "    class_set = []\n",
    "    for class_name in classes:\n",
    "        phone_modal = []\n",
    "        for feature in csv_files:\n",
    "            # Define file path\n",
    "            file_path = os.path.join(directory, class_name, \"Smartphone\", f\"{feature}.csv\")\n",
    "            \n",
    "            # Check if file exists\n",
    "            if os.path.isfile(file_path):\n",
    "                # Read each CSV file\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Convert DataFrame to numpy array and append to the list\n",
    "                df = df.iloc[:, :-2]\n",
    "                phone_modal.append(df.values)\n",
    "            else:\n",
    "                #print(f\"File {file_path} not found.\")\n",
    "                phone_modal.append(['not available'])\n",
    "        class_set.append(phone_modal)\n",
    "    client_set_phone[int(directory[-2:])-1] = class_set ##directory[-2:] retrieves the ID\n",
    "    # Now 'class_set' is a list of numpy arrays for each class in the current directory\n",
    "    # You can process it here before moving to the next directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0610fd",
   "metadata": {},
   "source": [
    "## 0-3 Speaker file reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# SMART SPEAKER ##########################################\n",
    "\n",
    "down_rate = 4\n",
    "# List of CSV files\n",
    "csv_files = ['Lacc', 'accel', 'gravity','gyro','mag','orientation','rotation']\n",
    "classes = ['Browsing on a Monitor','Hand Writing','Keyboard Typing','Reading Book',\n",
    "           'Stretching','Talking in Phone','walking and talking to phone',\n",
    "           'Walking Around','writing and talking to phone']\n",
    "\n",
    "# Base path\n",
    "base_path = \"H:/Arash/HAR/HAR_2023_dataset/2023 - FL - HAR/data/Synchronized HAR Data\" # Office PC\n",
    "# base_path = \"C:/NotWin/University/PhD/HAR/HAR_2023\"\n",
    "# base_path = \"D:/OneDrive_2023-06-01(1)/2023 - FL - HAR/data/Synchronized HAR Data\"\n",
    "base_path = \"E:/Software/HAR_2023_dataset/OneDrive_2023/Synchronized HAR Data\"\n",
    "\n",
    "\n",
    "# Get all directories within base_path that match the pattern\n",
    "directories = glob.glob(os.path.join(base_path, \"*-2023-*\"))\n",
    "\n",
    "client_set_speaker = [ [] for i in range(35)]\n",
    "# Loop through each matched directory\n",
    "for directory in directories:\n",
    "    class_set = []\n",
    "    for class_name in classes:\n",
    "        speaker_modal = []\n",
    "        for feature in csv_files:\n",
    "            # Define file path\n",
    "            file_path = os.path.join(directory, class_name, \"SmartSpeaker\", f\"audio.wav\")\n",
    "             # Check if file exists\n",
    "            if os.path.isfile(file_path):\n",
    "                # Read the wav file (mono)\n",
    "                sampling_rate, data = wavfile.read(file_path)\n",
    "\n",
    "                # For stereo, data will be an array with two columns\n",
    "                # If you want to convert it to mono\n",
    "                if len(data.shape) > 1:\n",
    "                    data = np.mean(data, axis=1)\n",
    "                data = decimate(data, down_rate)\n",
    "                speaker_modal.append(data)\n",
    "            else:\n",
    "                #print(f\"File {file_path} not found.\")\n",
    "                speaker_modal.append(['not available'])\n",
    "        class_set.append(speaker_modal)\n",
    "    client_set_speaker[int(directory[-2:])-1] = class_set ##directory[-2:] retrieves the ID\n",
    "    # Now 'class_set' is a list of numpy arrays for each class in the current directory\n",
    "    # You can process it here before moving to the next directory\n",
    "sampling_rate = int(sampling_rate/down_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25d1215",
   "metadata": {},
   "source": [
    "## 1-1 watch segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "def segment_data_watch(data, start_time, end_time, segment_size = 2, sampling_frequency = 64, overlap = 0.5):\n",
    "    # mode 0: input is x,y,z\n",
    "    # mode 0: input is x\n",
    "    mode = 1\n",
    "    if np.shape(data)[1] == 4:\n",
    "        mode = 0\n",
    "\n",
    "    timestamps = data[:,0]\n",
    "    x = data[:, 1]\n",
    "    if mode == 0:\n",
    "        y = data[:, 2]\n",
    "        z = data[:, 3]\n",
    "    \n",
    "    new_timestamps = np.arange(start_time, end_time, 1000/sampling_frequency)\n",
    "    # Interpolate the data\n",
    "    x_interpolated = interpolate.interp1d(timestamps, x,fill_value=\"extrapolate\")(new_timestamps)\n",
    "    if mode == 0:\n",
    "        y_interpolated = interpolate.interp1d(timestamps, y,fill_value=\"extrapolate\")(new_timestamps)\n",
    "        z_interpolated = interpolate.interp1d(timestamps, z,fill_value=\"extrapolate\")(new_timestamps)\n",
    "    \n",
    "    \n",
    "    resampled_data = np.column_stack((new_timestamps, x_interpolated))\n",
    "    if mode == 0:\n",
    "        resampled_data = np.column_stack((new_timestamps, x_interpolated, y_interpolated, z_interpolated))  \n",
    "    # Segment the data\n",
    "    segments = []\n",
    "    step_size = int(segment_size * sampling_frequency * (1 - overlap))\n",
    "    for i in range(0, len(resampled_data) - segment_size * sampling_frequency + 1, step_size):\n",
    "        segment = resampled_data[i:i + segment_size * sampling_frequency]\n",
    "        segments.append(segment)\n",
    "        \n",
    "    # Convert list of segments to numpy array\n",
    "    segments = np.array(segments)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07017df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Preparing local datasets\n",
    "OVERLAP = 0.2   # in precentage\n",
    "Sample_FREQ = 50 # in Htz\n",
    "seg_size = 2 #in second\n",
    "clean_clients = [x for x in range(35) if x not in [0,2,5,6,17,27,30]]\n",
    "local_datasets_watch = []\n",
    "for client_idx in clean_clients:\n",
    "\n",
    "    for class_id in range(9):\n",
    "        watch_modal = client_set_watch[client_idx][class_id]\n",
    "        for sig in range(4):\n",
    "            if sig == 0:\n",
    "                \n",
    "                start_time = watch_modal[sig][:,0][0]\n",
    "                end_time = watch_modal[sig][:,0][-1]\n",
    "                x_data = segment_data_watch(watch_modal[sig],start_time = start_time,\n",
    "                                        end_time = end_time, segment_size=seg_size, sampling_frequency=Sample_FREQ, overlap=OVERLAP)\n",
    "                x_data = x_data[...,1:] #exluding the timestamps\n",
    "                y_data = np.zeros([x_data.shape[0]]) + class_id  \n",
    "\n",
    "            else:\n",
    "                segments = segment_data_watch(watch_modal[sig],start_time = start_time,\n",
    "                                        end_time = end_time, segment_size=seg_size, sampling_frequency=Sample_FREQ, overlap=OVERLAP)\n",
    "                x_data = np.concatenate([x_data,segments[...,1:]],axis=-1)\n",
    "        if class_id == 0:\n",
    "            x_dataset = x_data\n",
    "            y_dataset = y_data\n",
    "            if client_idx == clean_clients[0]:\n",
    "                x_central_watch = x_dataset\n",
    "                y_central_watch = y_dataset\n",
    "        else:\n",
    "            x_dataset = np.concatenate([x_dataset,x_data],axis=0)\n",
    "            y_dataset = np.concatenate([y_dataset,y_data],axis=0)\n",
    "    local_datasets_watch.append( [x_dataset,y_dataset] )\n",
    "    x_central_watch = np.concatenate((x_central_watch,x_dataset))\n",
    "    y_central_watch = np.concatenate((y_central_watch,y_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc375a",
   "metadata": {},
   "source": [
    "## 1-2 Phone Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data_phone(data, segment_size=2, sampling_frequency=1000, overlap=0.5):\n",
    "    # Extract the columns\n",
    "    timestamps = data[:, 0]\n",
    "    x = data[:, 1]\n",
    "    y = data[:, 2]\n",
    "    z = data[:, 3]\n",
    "\n",
    "    # Create a new time array with stable frequency\n",
    "    new_timestamps = np.arange(timestamps[0], timestamps[-1], 1000/sampling_frequency)\n",
    "\n",
    "    # Interpolate the data\n",
    "    x_interpolated = interpolate.interp1d(timestamps, x)(new_timestamps)\n",
    "    y_interpolated = interpolate.interp1d(timestamps, y)(new_timestamps)\n",
    "    z_interpolated = interpolate.interp1d(timestamps, z)(new_timestamps)\n",
    "\n",
    "    # Resampled data\n",
    "    resampled_data = np.column_stack((new_timestamps, x_interpolated, y_interpolated, z_interpolated))\n",
    "\n",
    "    # Segment the data\n",
    "    segments = []\n",
    "    step_size = int(segment_size * sampling_frequency * (1 - overlap))\n",
    "    for i in range(0, len(resampled_data) - segment_size * sampling_frequency + 1, step_size):\n",
    "        segment = resampled_data[i:i + segment_size * sampling_frequency]\n",
    "        segments.append(segment)\n",
    "\n",
    "    # Convert list of segments to numpy array\n",
    "    segments = np.array(segments)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Preparing local and central datasets\n",
    "########## the local datasets the smarphone modality for each user will be stored as local_datasets_phone\n",
    "########## the centralized datastes of phone for all users will be stored as x_central_phone & y_central_phone\n",
    "\n",
    "OVERLAP = 0.2   # in precentage\n",
    "Sample_FREQ = 50 # in Htz\n",
    "seg_size = 2 #in second\n",
    "clean_clients = [x for x in range(35) if x not in [0,2,5,6,17,27,30]]\n",
    "local_datasets_phone = []\n",
    "for client_idx in clean_clients:\n",
    "    \n",
    "    for class_id in range(9):\n",
    "        phone_modal = client_set_phone[client_idx][class_id]\n",
    "    #     phone_modal = zero_score(phone_modal)\n",
    "        for sig in range(7):\n",
    "            if sig == 0:\n",
    "                x_data = segment_data_phone(phone_modal[sig],segment_size=seg_size, sampling_frequency=Sample_FREQ, overlap=OVERLAP)\n",
    "                x_data = x_data[...,1:] #exluding the timestamps\n",
    "                y_data = np.zeros([x_data.shape[0]]) + class_id\n",
    "\n",
    "            else:\n",
    "                segments = segment_data_phone(phone_modal[sig],segment_size=seg_size, sampling_frequency=Sample_FREQ, overlap=OVERLAP)\n",
    "                x_data = np.concatenate([x_data,segments[...,1:]],axis=-1)\n",
    "        if class_id == 0:\n",
    "            x_dataset_phone = x_data\n",
    "            y_dataset_phone = y_data\n",
    "            if client_idx == clean_clients[0]:\n",
    "                x_central_phone = x_dataset_phone\n",
    "                y_central_phone = y_dataset_phone\n",
    "        else:\n",
    "            x_dataset_phone = np.concatenate([x_dataset_phone,x_data],axis=0)\n",
    "            y_dataset_phone = np.concatenate([y_dataset_phone,y_data],axis=0)\n",
    "    local_datasets_phone.append( [x_dataset_phone,y_dataset_phone] )\n",
    "    x_central_phone = np.concatenate((x_central_phone,x_dataset_phone))\n",
    "    y_central_phone = np.concatenate((y_central_phone,y_dataset_phone))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a7acc5",
   "metadata": {},
   "source": [
    "## 1-3 Speaker Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07456bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def segment_audio(data, segment_size=2, sampling_frequency=1000, overlap=0.5):\n",
    "    # Segment the data\n",
    "    segments = []\n",
    "    step_size = int(segment_size * sampling_frequency * (1 - overlap))\n",
    "    for i in range(0, len(data) - segment_size * sampling_frequency + 1, step_size):\n",
    "        segment = data[i:i + segment_size * sampling_frequency]\n",
    "        segments.append(segment)\n",
    "\n",
    "    # Convert list of segments to numpy array\n",
    "    segments = np.array(segments)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f21da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERLAP = 0.20   # in precentage\n",
    "Sample_FREQ = sampling_rate # in Hz\n",
    "seg_size = 2 #in second\n",
    "def create_dataset(client_set,client_id, sample_freq, segment_size, overlap):\n",
    "    for class_id in range(9):\n",
    "        speaker_modal = client_set[client_id][class_id]\n",
    "    #     phone_modal = zero_score(phone_modal)\n",
    "        for sig in range(7):\n",
    "            if sig == 0:\n",
    "                x_data = segment_audio(speaker_modal[sig],segment_size=seg_size, sampling_frequency=Sample_FREQ, overlap=OVERLAP)\n",
    "                seg_end = x_data.shape[1]-1\n",
    "                wind_end = x_data.shape[0]-1\n",
    "#                 x_data = x_data[...,1:] #exluding the timestamps\n",
    "                y_data = np.zeros([wind_end]) + class_id\n",
    "\n",
    "            else:\n",
    "                segments = segment_audio(speaker_modal[sig],segment_size=seg_size, sampling_frequency=Sample_FREQ, overlap=OVERLAP)\n",
    "                x_data = np.concatenate((x_data[:wind_end,:seg_end],segments[:wind_end,:seg_end]),axis=-1)\n",
    "        if class_id == 0:\n",
    "            x_dataset = x_data\n",
    "            y_dataset = y_data\n",
    "        else:\n",
    "            x_dataset = np.concatenate([x_dataset,x_data],axis=0)\n",
    "            y_dataset = np.concatenate([y_dataset,y_data],axis=0)\n",
    "    return x_dataset, y_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "Y_data = []\n",
    "for id in range(35):\n",
    "    if id == 31-1 or id==1-1 or id ==7-1 or id ==28-1 or id ==3-1 or id ==6-1 or id==18-1:\n",
    "        continue\n",
    "    x_dataset, y_dataset = create_dataset(client_set,id, Sample_FREQ, seg_size, OVERLAP)\n",
    "    X_data.append(x_dataset)\n",
    "    Y_data.append(y_dataset)\n",
    "    \n",
    "print(y_dataset.shape)\n",
    "print(x_dataset.shape) ## (data sample, sequence of the signal, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8e693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def calculate_features(signal, sampling_rate=16000, n_mfcc=13):\n",
    "    # Calculate the MFCCs for the signal\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "    \n",
    "#     Calculate the Chroma feature\n",
    "    chroma = librosa.feature.chroma_stft(y=signal, sr=sampling_rate)\n",
    "    \n",
    "    # Calculate the Spectral Contrast\n",
    "#     spec_contrast = librosa.feature.spectral_contrast(y=signal, sr=sampling_rate)\n",
    "    \n",
    "    # Calculate the Tonnetz\n",
    "#     tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(signal), sr=sampling_rate)\n",
    "    \n",
    "    # Concatenate the features into one array\n",
    "    features = np.concatenate([mfccs, chroma], axis=0)\n",
    "#     features = mfccs\n",
    "    return features\n",
    "\n",
    "# Your dataset\n",
    "x_dataset = X_data[0]\n",
    "\n",
    "# New dataset\n",
    "\n",
    "New_X_data = []\n",
    "for client in range(len(X_data)):\n",
    "    new_x_dataset = []\n",
    "    # Iterate over the samples in the dataset\n",
    "    for sample in X_data[client]:\n",
    "        # Calculate the features for each signal\n",
    "        new_sample = calculate_features(sample,sampling_rate = sampling_rate)\n",
    "\n",
    "        # Add the new sample to the new dataset\n",
    "        new_x_dataset.append(new_sample)\n",
    "\n",
    "    # Now new_x_dataset is a list of the same structure as x_dataset, but with the audio signals replaced by their features\n",
    "    new_x_dataset = np.array(new_x_dataset)\n",
    "    New_X_data.append(new_x_dataset)\n",
    "    print(f\"extracting features for client {client}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ad992",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_datasets_audio_x = New_X_data\n",
    "local_datasets_audio_y = Y_data \n",
    "N = 0\n",
    "for i in range(28):\n",
    "    N = N + len(local_datasets_audio_y[i])\n",
    "\n",
    "for i in range(28):\n",
    "    if i == 0:\n",
    "        x_centralized_audio = local_datasets_audio_x[i]\n",
    "        y_centralized_audio = local_datasets_audio_y[i]\n",
    "\n",
    "    else:\n",
    "        x_centralized_audio = np.concatenate([x_centralized_audio,local_datasets_audio_x[i]])\n",
    "        y_centralized_audio = np.concatenate([y_centralized_audio,local_datasets_audio_y[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d7433",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_datasets_audio = list()\n",
    "for i in range(28):\n",
    "    local_datasets_audio.append([New_X_data[i], Y_data[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64bd46",
   "metadata": {},
   "source": [
    "## 3- Aligning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ff8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aligning test data from phone and watch\n",
    "aligned_data = list()\n",
    "local_paired_watch = []\n",
    "local_paired_phone = []\n",
    "local_paired_audio = []\n",
    "local_paired_label = []\n",
    "for client in range(28):\n",
    "    for i in range(9):\n",
    "        indices_phone = np.where(np.array(local_datasets_phone[client][1]) == i)[0]\n",
    "        indices_watch = np.where(np.array(local_datasets_watch[client][1]) == i)[0]\n",
    "        indices_audio = np.where(np.array(local_datasets_audio[client][1]) == i)[0]\n",
    "        min_len = np.min([len(indices_phone),len(indices_watch),len(indices_audio)])\n",
    "        if i == 0:\n",
    "            paired_label = local_datasets_watch[client][1][indices_watch[0:min_len]]\n",
    "            \n",
    "            paired_watch = local_datasets_watch[client][0][indices_watch[0:min_len]]\n",
    "            paired_phone = local_datasets_phone[client][0][indices_phone[0:min_len]]\n",
    "            paired_audio = local_datasets_audio[client][0][indices_audio[0:min_len]]\n",
    "        else:\n",
    "            paired_label = np.concatenate([paired_label,local_datasets_watch[client][1][indices_watch[0:min_len]]])\n",
    "            \n",
    "            paired_watch = np.concatenate([paired_watch,local_datasets_watch[client][0][indices_watch[0:min_len]]])\n",
    "            paired_phone = np.concatenate([paired_phone,local_datasets_phone[client][0][indices_phone[0:min_len]]])\n",
    "            paired_audio = np.concatenate([paired_audio,local_datasets_audio[client][0][indices_audio[0:min_len]]])\n",
    "        for j in range(min_len):\n",
    "            aligned_watch_data = local_datasets_watch[client][0][indices_watch[j]]\n",
    "            aligned_phone_data = local_datasets_phone[client][0][indices_phone[j]]\n",
    "            aligned_audio_data = local_datasets_audio[client][0][indices_audio[j]]\n",
    "            aligned_labels = local_datasets_phone[client][1][indices_phone[j]]\n",
    "            aligned_data.append([aligned_phone_data,aligned_watch_data,aligned_audio_data,aligned_labels])\n",
    "    \n",
    "    local_paired_label.append(paired_label)\n",
    "    \n",
    "    local_paired_watch.append(paired_watch)\n",
    "    local_paired_phone.append(paired_phone)\n",
    "    local_paired_audio.append(paired_audio)\n",
    "\n",
    "print(len(aligned_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Shuffle\n",
    "for i in range(28):\n",
    "    combined_data = list(zip(local_paired_watch[i],local_paired_phone[i], local_paired_audio[i], local_paired_label[i]))\n",
    "    # Shuffle the combined data\n",
    "    np.random.shuffle(combined_data)\n",
    "    # Unzip the shuffled data\n",
    "    local_paired_watch[i], local_paired_phone[i], local_paired_audio[i],local_paired_label[i] = zip(*combined_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
