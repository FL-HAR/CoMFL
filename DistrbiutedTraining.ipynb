{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed00827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from google.colab import drive\n",
    "import pickle\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import decimate\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a79a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aggregation functions\n",
    "\n",
    "def scaled_weights(model, scale):\n",
    "    weights = model.get_weights()\n",
    "    for layer_idx in range(len(weights)):\n",
    "        weights[layer_idx] = weights[layer_idx] * scale\n",
    "    return weights\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "\n",
    "    return avg_grad\n",
    "\n",
    "def choose_model(i):\n",
    "  if 0 <= i <= 2:\n",
    "    f = Uni_Modal(i)\n",
    "  elif i == 3:\n",
    "    f = Multi_Modal()\n",
    "  elif i == 10:\n",
    "    f = PS2W()\n",
    "  elif i == 11:\n",
    "    f = P2W()\n",
    "  elif i == 12:\n",
    "    f = S2W()\n",
    "  return f\n",
    "\n",
    "\n",
    "def choose_data(i):\n",
    "  if i == 0:\n",
    "    train_x = local_paired_phone_train\n",
    "    train_y = local_paired_label_train\n",
    "    test_x = global_paired_phone_test\n",
    "    test_y = global_paired_label_test\n",
    "  elif i == 1:\n",
    "    train_x = local_paired_watch_train\n",
    "    train_y = local_paired_label_train\n",
    "    test_x = global_paired_watch_test\n",
    "    test_y = global_paired_label_test\n",
    "  elif i == 2:\n",
    "    train_x = local_paired_audio_train\n",
    "    train_y = local_paired_label_train\n",
    "    test_x = global_paired_audio_test\n",
    "    test_y = global_paired_label_test\n",
    "  elif i == 3:\n",
    "    train_x = [local_paired_watch_train,local_paired_phone_train,local_paired_audio_train]\n",
    "    train_y = local_paired_label_train\n",
    "    test_x = [global_paired_watch_test,global_paired_phone_test,global_paired_audio_test]\n",
    "    test_y = global_paired_label_test\n",
    "  elif i == 4:\n",
    "    train_x = central_paired_phone_train\n",
    "    train_y = central_paired_label_train\n",
    "    test_x = global_paired_phone_test\n",
    "    test_y = global_paired_label_test\n",
    "  elif i == 5:\n",
    "      train_x = central_paired_watch_train\n",
    "      train_y = central_paired_label_train\n",
    "      test_x = global_paired_watch_test\n",
    "      test_y = global_paired_label_test\n",
    "  elif i == 6:\n",
    "      train_x = central_paired_audio_train\n",
    "      train_y = central_paired_label_train\n",
    "      test_x = global_paired_audio_test\n",
    "      test_y = global_paired_label_test\n",
    "  elif i == 7:\n",
    "      train_x = [central_paired_watch_train, central_paired_phone_train,\\\n",
    "                 central_paired_audio_train]\n",
    "      train_y = central_paired_label_train\n",
    "      test_x = [global_paired_watch_test, global_paired_phone_test,\\\n",
    "                 global_paired_audio_test]\n",
    "      test_y = global_paired_label_test\n",
    "  return train_x,train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedL(mode, Train_x, Train_y, Test_x, Test_y, comm_rounds = 100,local_epochs = 3,batch_size = 32, num_select_per_round = 20,num_clients = 20):\n",
    "# mode => 0: Phone, 1:Watch, 2: Speaker, 3: Multi-Modal\n",
    "  global_model = choose_model(mode)\n",
    "  W_t_1 = global_model.get_weights()\n",
    "  W_t = W_t_1\n",
    "\n",
    "  num_samples =np.array([len(Train_y[idx]) for idx in range(num_clients)])\n",
    "\n",
    "  global_acc = list()\n",
    "  acc_out_list = list()\n",
    "\n",
    "  for t in range(comm_rounds):\n",
    "    scaled_weight_list = []\n",
    "    #Randomly selecting \"num_candidates\" candidates from \"num_clients\" clients\n",
    "    participant_idx = random.sample(range(num_clients), num_select_per_round)\n",
    "    participant_idx = np.sort(participant_idx)\n",
    "    W_t = global_model.get_weights()\n",
    "    FedAvg_scales = num_samples/sum(num_samples[participant_idx])\n",
    "    #loop through each client and create new local model\n",
    "    for client in participant_idx:\n",
    "      #local_model = global_model\n",
    "      local_model = choose_model(mode)\n",
    "\n",
    "      #set local model weight to the weight of the global model\n",
    "      local_model.set_weights(W_t)\n",
    "      #fit local model with client's data\n",
    "      if mode == 3:\n",
    "        local_model.fit([Train_x[0][client].reshape((-1,25,24,1)),Train_x[1][client],Train_x[2][client]],Train_y[client], epochs=local_epochs, verbose=0,batch_size = batch_size)\n",
    "      elif mode == 10:\n",
    "        local_model.fit([Train_x[0][client],Train_x[1][client]],Train_y[client], epochs=local_epochs, verbose=0,batch_size = batch_size)\n",
    "      else:\n",
    "        local_model.fit(Train_x[client],Train_y[client], epochs=local_epochs, verbose=0,batch_size = batch_size)\n",
    "\n",
    "      # aggregation\n",
    "      scaled_weight_list.append(scaled_weights(local_model,FedAvg_scales[client]))\n",
    "      #K.clear_session()\n",
    "\n",
    "    average_weights = sum_scaled_weights(scaled_weight_list)\n",
    "    global_model.set_weights(average_weights)\n",
    "    _,acc_FedAvg = global_model.evaluate(Test_x, Test_y,verbose = 0)\n",
    "    #acc_FedAvg = global_model.evaluate(Test_x, Test_y,verbose = 0)\n",
    "    global_acc.append(acc_FedAvg)\n",
    "    print('communication round',t, '|', 'global accuracy:',acc_FedAvg)\n",
    "    print('------------------------------------------------')\n",
    "\n",
    "  return global_model, global_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35937b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distributed training for Watch Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ef2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 1\n",
    "train_x = local_train_x_w\n",
    "train_y = local_train_y\n",
    "\n",
    "test_x = central_test_x_w\n",
    "test_y = central_test_y\n",
    "global_model, global_acc = FedL(comm_rounds=100,mode= mode, Train_x = train_x, Train_y = train_y, Test_x = test_x, Test_y = test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distributed training for Phone Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f263d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 0\n",
    "train_x = local_train_x_p\n",
    "train_y = local_train_y\n",
    "\n",
    "test_x = central_test_x_p\n",
    "test_y = central_test_y\n",
    "global_model, global_acc = FedL(comm_rounds=100,mode= mode, Train_x = train_x, Train_y = train_y, Test_x = test_x, Test_y = test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e16f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distributed training for Speaker Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95152cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 2\n",
    "train_x = local_train_x_s\n",
    "train_y = local_train_y\n",
    "\n",
    "test_x = central_test_x_s\n",
    "test_y = central_test_y\n",
    "global_model, global_acc = FedL(comm_rounds=100,mode= mode, Train_x = train_x, Train_y = train_y, Test_x = test_x, Test_y = test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca39034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
